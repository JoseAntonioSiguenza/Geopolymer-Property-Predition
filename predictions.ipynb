{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install and imports"
      ],
      "metadata": {
        "id": "3fcd5sLdVNMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac2bd68-a9d8-4ea1-f124-0f670a5a42e5",
        "id": "WqzqpYnmYMuR"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.2)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9263bd6c-14f0-47a4-fea9-9580b2fd2fdf",
        "id": "TlNo4LzhYMuS"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "cM2hsFe5YMuT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize random seed"
      ],
      "metadata": {
        "id": "u5YMvFsnVvOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "id": "EkaxpVn1YMuT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload images to predict tensile strength"
      ],
      "metadata": {
        "id": "fOsniDm3V3BI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To access the data file from google drive\n",
        "# If you have you files locally, plesea ignore this code block\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b606e98-36b3-4d21-914b-779d15cb3843",
        "id": "2m_ATD6BYMuT"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IMWCNMn2YMuT"
      },
      "outputs": [],
      "source": [
        "# Path of the image\n",
        "image_path = \"/content/drive/MyDrive/Tesis_Salvador/\"\n",
        "image_list = os.listdir(image_path+\"2023/\") + os.listdir(image_path+\"2024/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "zZ0SXXIBWbXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images from path\n",
        "def load_images(image_path, image_list):\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  i =0\n",
        "  for image_name in image_list:\n",
        "      if i < 26:\n",
        "        path = os.path.join(image_path, \"2023/\"+image_name)\n",
        "      else:\n",
        "        path = os.path.join(image_path, \"2024/\"+image_name)\n",
        "      image = Image.open(path,)\n",
        "      image = image.resize((250, 250))\n",
        "\n",
        "      # Convert to GrayScale\n",
        "      if image.mode != 'L':\n",
        "          image = image.convert('L')\n",
        "\n",
        "\n",
        "      image_array = np.array(image)\n",
        "      images.append(image_array)\n",
        "\n",
        "\n",
        "      if image_name.startswith(\"G0\"):\n",
        "          labels.append(5.72)\n",
        "      elif image_name.startswith(\"G2\"):\n",
        "          labels.append(4.31)\n",
        "      elif image_name.startswith(\"G3\"):\n",
        "          labels.append(4.18)\n",
        "      elif image_name.startswith(\"G5\"):\n",
        "          labels.append(2.72)\n",
        "      elif image_name.startswith(\"G7\"):\n",
        "          labels.append(2.67)\n",
        "\n",
        "      elif image_name.startswith(\"Gi0\"):\n",
        "          labels.append(4.06)\n",
        "      elif image_name.startswith(\"Gi2\"):\n",
        "          labels.append(6.23)\n",
        "      elif image_name.startswith(\"Gi3\"):\n",
        "          labels.append(5.22)\n",
        "      elif image_name.startswith(\"Gi5\"):\n",
        "          labels.append(4.11)\n",
        "      elif image_name.startswith(\"Gi7\"):\n",
        "          labels.append(3.85)\n",
        "\n",
        "      i+=1\n",
        "\n",
        "\n",
        "  images = np.array(images)\n",
        "  images = images.reshape(-1, 250, 250, 1)\n",
        "  images = tf.convert_to_tensor(images/255, dtype=tf.float32)\n",
        "  labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
        "  return images, labels\n",
        "\n",
        "# Custom accuracy metric\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    return K.mean(K.abs(y_true - y_pred) / K.maximum(K.abs(y_true), K.epsilon()), axis=-1)\n",
        "\n",
        "# To include GrayScale to RGB conversion\n",
        "@keras.utils.register_keras_serializable()\n",
        "def preprocess_grayscale_to_rgb(input_image):\n",
        "    return tf.image.grayscale_to_rgb(input_image)\n",
        "\n",
        "# Predictions with a given model on input images\n",
        "def preds(model, images, labels):\n",
        "\n",
        "  loaded_model = tf.keras.models.load_model(model, custom_objects={'custom_accuracy': custom_accuracy})\n",
        "  # Predictions\n",
        "  predictions = loaded_model.predict(images)\n",
        "  count = 0\n",
        "  for i in range(len(predictions)):\n",
        "      error = float(abs(predictions[i] - labels[i]) * 100 / labels[i])\n",
        "      if error <= 5.00:\n",
        "          count += 1\n",
        "\n",
        "  print(f\"Hits within 5% error: {count/len(predictions)}\")\n",
        "\n",
        "  count = 0\n",
        "  for i in range(len(predictions)):\n",
        "      error = float(abs(predictions[i] - labels[i]) * 100 / labels[i])\n",
        "      if error <= 10.00:\n",
        "          count += 1\n",
        "\n",
        "  print(f\"Hits within 10% error: {count/len(predictions)}\")\n",
        "  return predictions\n"
      ],
      "metadata": {
        "id": "jC4TtAd8YMuT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RnBCjBsPFxB",
        "outputId": "c11110ad-4f4d-4743-c14e-edc0477e09dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step\n",
            "Hits within 5% error: 0.8181818181818182\n",
            "Hits within 10% error: 0.8863636363636364\n"
          ]
        }
      ],
      "source": [
        "images, labels = load_images(image_path, image_list)\n",
        "predictions = preds('optimal_hyperparameters_transfer_learning_model.h5', images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBU47-nHKOSh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}